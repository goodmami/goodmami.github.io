<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <title>Michael Wayne Goodman</title>
  <link href="https://fonts.googleapis.com/css?family=Ubuntu" rel="stylesheet">
  <script defer src="https://use.fontawesome.com/releases/v5.0.12/js/all.js" integrity="sha384-Voup2lBiiyZYkRto2XWqbzxHXwzcm4A5RfdfG6466bu5LqjwwrjXCMBQBLMWh7qR"
    crossorigin="anonymous"></script>
  <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">
  <link rel="stylesheet" type="text/css" href="/static/css/main.css" />
</head>

<body>
  <header>
    <div class="center">
      <h1> <a href="/">Michael Wayne Goodman</a> </h1>
      <h2> Computational Linguist </h2>
      <nav>
        <ul>
          <li> <a href="/publications.html"> publications </a> </li>
          <li> <a href="/projects.html"> projects </a> </li>
          <li> <a href="/blog.html"> blog </a> </li>
          <li> <a href="mailto:goodman.m.w@gmail.com"> contact </a> </li>
        </ul>
      </nav>
      <ul>
        <li><a href="https://github.com/goodmami"><i title="GitHub" class="fab fa-github"></i></a></li>
        <li><a href="https://stackoverflow.com/users/1441112/goodmami"><i title="StackOverflow" class="fab fa-stack-overflow"></i></a></li>
        <li><a href="https://www.linkedin.com/in/michael-wayne-goodman"><i title="LinkedIn" class="fab fa-linkedin"></i></a></li>
        <li><a href="https://scholar.google.com/citations?user=04Hg4PAAAAAJ"><i title="Google Scholar" class="ai ai-google-scholar-square"></i></a></li>
        <li><a href="https://www.researchgate.net/profile/Michael_Goodman5"><i title="ResearchGate" class="fab fa-researchgate"></i></a></li>
        <li><a href="https://www.semanticscholar.org/author/Michael-Wayne-Goodman/1939647"><i title="Semantic Scholar" class="ai ai-semantic-scholar fakesquare"></i></a> </li>
      </ul>
    </div>
  </header>

  <section>
    <div class="logo">
      <img src="/static/me.png" /> </div>
    <h2>About</h2>
    <p> I am a computational linguist living in Singapore. My primary research interests include:</p>
    <ul>
      <li>Representations of knowledge and formal semantics</li>
      <li>Machine translation</li>
      <li>Natural language understanding</li>
      <li>Natural language generation</li>
      <li>Grammar development</li>
      <li>Resource development for low-resource languages</li>
    </ul>
    <p>
      I'm currently a postdoctoral research fellow in the <a href="https://soh.ntu.edu.sg/">School of Humanities</a> at <a href="https://ntu.edu.sg/">Nanyang Technological University</a>.

      Here is my <a href="/static/goodman-cv.pdf"><i class="fas fa-file-pdf"></i> CV</a>.
    </p>
  </section>

  <section>
    <h2>Selected Publications <span class="hextra"><a href="/publications.html">all publications...</a></span></h2>

    <ul class="publications">
      <li>
	<span class="author">Michael Wayne Goodman.</span>
	<span class="title">AMR Normalization for Fairer Evaluation.</span>
	<span>(to appear) Proceedings of the 33rd Pacific Asia Conference on Language, Information, and Computation (PACLIC 33).</span>
	<span>2019.</span>
	<div class="publinks">
	  <a class="show-modal"><i class="fas fa-file-alt"></i> Abstract</a>
          <p class="modal">Abstract Meaning Representation (AMR; Banarescu et al., 2013) encodes the meaning of sentences as a directed graph and Smatch (Cai and Knight, 2013) is the primary metric for evaluating AMR graphs. Smatch, however, is unaware of some meaning-equivalent variations in graph structure allowed by the AMR Specification and gives different scores for AMRs exhibiting these variations. In this paper I propose four normalization methods for helping to ensure that conceptually equivalent AMRs are evaluated as equivalent. Equivalent AMRs with and without normalization can look quite different---comparing a gold corpus to itself with relation reification alone yields a difference of 25 Smatch points, suggesting that the outputs of two systems may not be directly comparable without normalization. The algorithms described in this paper are implemented on top of an existing open-source Python toolkit for AMR and will be released under the same license.</p>
          <a href="/static/bib/goodman-2019.bib"><i class="fas fa-quote-right"></i> bib</a>
        </div>
      </li>
      <li>
	<span class="author">Valerie Hajdik, Jan Buys, Michael Wayne Goodman, and Emily M. Bender.</span>
	<span class="title">Neural Text Generation from Rich Semantic Representations.</span>
	<span>Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT).</span>
	<span>2019.</span>
	<div class="publinks">
	  <a class="show-modal"><i class="fas fa-file-alt"></i> Abstract</a>
          <a href="https://www.aclweb.org/anthology/N19-1235"><i class="fas fa-file-pdf"></i> Paper</a>
          <p class="modal">We propose neural models to generate high-quality text from structured representations based on Minimal Recursion Semantics (MRS). MRS is a rich semantic representation that encodes more precise semantic detail than other representations such as Abstract Meaning Representation (AMR). We show that a sequence-to-sequence model that maps a linearization of Dependency MRS, a graph-based representation of MRS, to text can achieve a BLEU score of 66.11 when trained on gold data. The performance of the model can be improved further using a high-precision, broad coverage grammar-based parser to generate a large silver training corpus, achieving a final BLEU score of 77.17 on the full test set, and 83.37 on the subset of test data most closely matching the silver data domain. Our results suggest that MRS-based representations are a good choice for applications that need both structured semantics and the ability to produce natural language text as output.</p>
          <a href="https://aclweb.org/anthology/papers/N/N19/N19-1235.bib"><i class="fas fa-quote-right"></i> bib</a>
        </div>
      </li>
      <li>
        <span class="author"> Ann A. Copestake, Guy Emerson, Michael Wayne Goodman, Matic Horvat, Alexander Kuhnle, and Ewa Muszynska.
        </span>
        <span class="title"> Resources for building applications with Dependency Minimal Recursion Semantics. </span>
        <span>Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC 2016).</span>
        <div class="publinks">
          <a href="http://www.lrec-conf.org/proceedings/lrec2016/pdf/634_Paper.pdf"><i class="fas fa-file-pdf"></i> Paper</a>
          <a class="show-modal"><i class="fas fa-file-alt"></i> Abstract</a>
          <p class="modal">We describe resources aimed at increasing the usability of the semantic representations utilized within the DELPH-IN (Deep Linguistic Processing with HPSG) consortium. We concentrate in particular on the Dependency Minimal Recursion Semantics (DMRS) formalism, a graph-based representation designed for compositional semantic representation with deep grammars. Our main focus is on English, and specifically English Resource Semantics (ERS) as used in the English Resource Grammar. We first give an introduction to ERS and DMRS and a brief overview of some existing resources and then describe in detail a new repository which has been developed to simplify the use of ERS/DMRS. We explain a number of operations on DMRS graphs which our repository supports, with sketches of the algorithms, and illustrate how these operations can be exploited in application building. We believe that this work will aid researchers to exploit the rich and effective but complex DELPH-IN resources.</p>
          <a href="/static/bib/copestake-et-al-2016.bib"><i class="fas fa-quote-right"></i> bib</a>
        </div>
      </li>
    </ul>
  </section>

  <section>
    <h2>
      Selected Projects
      <span class="hextra"><a href="/projects.html">more projects...</a></span>
    </h2>

    <ul class="projects">
      <li class="clear">
        <figure>
          <img alt="DELPHIN-Viz screenshot" src="/static/pydelphin-screenshot.png" />
          <figcaption>The <a href="http://delph-in.github.com/delphin-viz/demo">DELPHIN-Viz demo</a> uses PyDelphin to interface a parser and to convert representations. This is a DMRS visualization of a Japanese sentence.</figcaption>
        </figure>
        <h3>PyDelphin <span class="hextra"><a href="https://github.com/delph-in/pydelphin"><i title="GitHub" class="fab fa-github"></i> GitHub Project</a></span></h3>
        <p>
          An open-source library for working with Minimal Recursion Semantics,
          [incr tsdb()] test suites, TDL code, and other representations used
          in HPSG grammars as produced within the
          <a href="http://delph-in.net">DELPH-IN</a> consortium.
        </p>
      </li>

      <li class="clear">
        <figure>
          <img alt="Xigt visualization screenshot" src="/static/xigt-screenshot.png" />
          <figcaption>
            Xigt data can be visualized to highlight interlinear relationships. This
            <a href="https://en.wikipedia.org/wiki/Yaqui_language">Yaqui [yaq]</a> example from the
            <a href="http://depts.washington.edu/uwcl/odin/">ODIN corpus</a> comes from
            <span class="title">Complement Types of Perception Verbs in Yaqui</span>
            (<a href="http://www.acsu.buffalo.edu/~rrgpage/rrg/RRG2004%20Book%20of%20Proceedings.pdf#page=92">Guerrero, 2004</a>).
          </figcaption>
        </figure>
        <h3>Xigt <span class="hextra"><a href="https://github.com/xigt"><i title="GitHub" class="fab fa-github"></i> GitHub Organization</a></span></h3>
        <p>
          A framework for working with interlinear glossed text, including the
          eponymous Xigt data model that uses a flat structure with ID-references
          in order to accommodate non-projective annotations, e.g., for annotating
          semantic dependencies.
        </p>
      </li>

      <li class="clear">
          <figure>
          <img alt="XMT dataflow diagram" src="/static/xmt-diagram.png" />
          <figcaption>
            XMT defines a workflow for automatically learning transfer rules for rule-based machine translation.
          </figcaption>
        </figure>
        <h3>XMT <span class="hextra"><a href="https://github.com/goodmami/xmt"><i title="GitHub" class="fab fa-github"></i> GitHub Project</a></span></h3>
        <p>
          A processing pipeline and related scripts for transfer-based machine translation
          in the <a href="http://moin.delph-in.net/LogonTop">LOGON</a> paradigm. This project
          forms the bulk of the task-specific code I used for my Ph.D. research, although it
          may be useful for others working in a similar space.
        </p>
      </li>
    </ul>
  </section>

  <section>
    <h2>
      Education and Experience
      <span class="hextra"><a href="/static/goodman-cv.pdf"><i class="fas fa-file-pdf"></i> CV</a></span>
    </h2>
    <ul class="fa-ul">
      <li>
          <span class="fa-li">
            <i class="fas fa-briefcase"></i>
          </span>
          <p>Postdoctoral Research Fellow, Nanyang Technological University, February 2019&ndash;</p>
      </li>
      <li>
        <span class="fa-li">
          <i class="fas fa-graduation-cap"></i>
        </span>
        <p>Ph.D. Linguistics, University of Washington, June 2018</p>
        <p>
          Dissertation:&nbsp;
          <a href="/static/goodman-dissertation.pdf">
            <i class="fas fa-file-pdf"></i>
            <i>Semantic Operations for Transfer-based Machine Translation</i>
          </a>
        </p>
      </li>
      <li>
          <span class="fa-li">
            <i class="fas fa-briefcase"></i>
          </span>
          <p>Research Associate, Nanyang Technological University, April 2014&ndash;August 2015</p>
      </li>
      <li>
        <span class="fa-li">
          <i class="fas fa-graduation-cap"></i>
        </span>
        <p>MA Computational Linguistics, University of Washington, August 2009</p>
        <p>
          Thesis:&nbsp;
          <a href="/static/goodman-ma-thesis.pdf">
            <i class="fas fa-file-pdf"></i>
            <i>Egad: Efficiently Evaluating and Extracting Errors from Deep Grammars</i>
          </a>
        </p>
      </li>
      <li>
          <span class="fa-li">
            <i class="fas fa-briefcase"></i>
          </span>
          <p>Contractor for Microsoft Translator, Microsoft Research (Populus Group), February 2009&ndash;June 2009</p>
      </li>
      <li>
          <span class="fa-li">
            <i class="fas fa-briefcase"></i>
          </span>
          <p>Invited Advisor, National Institute of Information and Communications Technology (NICT / 情報通信研究機構), October 2008&ndash;January 2009</p>
      </li>
      <li>
        <span class="fa-li">
          <i class="fas fa-graduation-cap"></i>
        </span>
        <p>BS Computer Science, Oregon State University, August 2007</p>
      </li>
    </ul>
  </section>

  <footer>
    <div class="center">
      <p>Updated: 2019-08-23</p>
      <img src="/static/eclipse-viewing.jpg"
           alt="My family and I viewing the solar eclipse on August 21, 2017."
	   title="Viewing the total solar eclipse in Corvallis, Oregon." />
    </div>
  </footer>
</body>

</html>
